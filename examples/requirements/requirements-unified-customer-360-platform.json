{
  "project_name": "Unified Customer-360 Platform",
  "problem_statement": "We're a multinational financial services company with highly fragmented systems across regions. In North America, we're still on a 20-year-old COBOL mainframe that handles core banking. In Europe, we're half-migrated to a cloud-native solution on Azure with microservices, but regulatory requirements force us to keep some workloads on-prem. In APAC, we outsourced development to a vendor who built an entirely different stack in Java, and we have little visibility into how it works. The board wants a unified customer-360 platform that: Can surface real-time transaction data across all regions. Is compliant with wildly different regulations (GDPR, CCPA, local APAC rules). Must support both event-driven architectures and batch jobs. Needs to integrate with legacy systems without a full rewrite. Must be designed in a way that's cloud-agnostic, since the company's CIO is wary of lock-in. Oh, and they want a proof of concept in six months and a full rollout plan within two years, with the understanding that half the stakeholders can't agree on what 'success' even means.",
  "solution_summary": "From my perspective, what would make this useful is if the platform abstracted away the regional and regulatory fragmentation so that: We can define a single 'customer object' with consistent attributes. Data can be queried and reconciled across systems in near real-time without violating compliance. The architecture supports progressive migration: legacy mainframe in NA, partial cloud in EU, outsourced Java mess in APAC — all plugged into a unified model without forcing an overnight rewrite. So no — it's not just a data aggregation layer, or just a dashboard, or just a new front-end. It's a governed data fabric with operational surfaces — something that lets different stakeholders get their slice of 'success' without locking us into one definition prematurely.",
  "data_inputs": "Customer data from COBOL mainframe (North America), Azure microservices (Europe), outsourced Java stack (APAC), transaction data, regulatory compliance data",
  "data_outputs": "Unified customer objects, real-time transaction streams, compliance audit trails, operational dashboards, API responses, embedded widgets",
  "processing_requirements": "Event sourcing with CQRS, CDC-based streaming, federated queries, batch ETL for legacy systems, real-time data reconciliation, automated compliance enforcement, progressive migration support",
  "user_interface": "Different groups will need different interaction patterns. Developers will expect an API-first approach with consistent schemas across regions. Operations staff will need web dashboards that consolidate customer data without forcing them to learn new tools. Executives will want lightweight reporting surfaces, probably embedded in the BI platforms they already use. Marketing may push for embedded widgets inside their campaign tools. The platform has to be multi-surface by design, not one-size-fits-all.",
  "frequency": "It will be a mix. Operations will hit it constantly with high-frequency transactional queries during every customer interaction. Finance and back office teams will drive periodic batch reconciliation jobs, often overnight. Marketing and analytics will expect near real-time event streaming for segmentation and targeting. Governance and compliance features will be invoked heavily during audits or regulatory events, but day to day most teams will try to work around them unless the enforcement is automated and transparent.",
  "complexity": "complex",
  "success_criteria": "I'll know it's working if front-line staff can pull up a complete, accurate customer view in under two seconds regardless of region, if regulators stop issuing fines for compliance gaps, and if developers can build new customer-facing features without weeks of manual data stitching.",
  "constraints": "If the platform required customer data to leave its region of origin, it would be dead on arrival because of GDPR and APAC residency laws. If integration timelines forced a big-bang migration off the mainframe, it would fail since the business can't tolerate more than incremental cutovers. If the solution introduced latency that made real-time operations slower than the legacy systems, adoption would collapse. And if compliance controls required manual processes instead of automated enforcement, regulators might approve it but the business would quietly abandon it.",
  "deal_breakers": "Customer data leaving its region of origin, big-bang migration requirements, latency worse than legacy systems, manual compliance processes",
  "frustration_triggers": "I'd recommend killing it if we end up with yet another siloed system that duplicates effort, if latency makes it unusable in real operations, or if the governance framework becomes so rigid that teams revert to shadow IT to get work done.",
  "technical_requirements": "I'd lean toward an event-sourcing model with CQRS where possible, using CDC-based streaming from systems that can support it to keep the customer object updated in near real time. For workloads that can't handle streaming, federated queries could provide on-demand access without forcing full migrations. The mainframe should be integrated first through CDC or log-based replication for critical data, but we'll still need batch ETL for legacy reports and reconciliations. An API gateway would be layered on top only where the mainframe can safely expose functions without risking stability.",
  "operational_constraints": "Deployment has to be hybrid by design. The mainframe stays on-prem with lightweight connectors and replication agents. The European cloud workloads live on Azure but must use containerized services that could be redeployed elsewhere if needed. The outsourced Java stack in APAC should be wrapped in standard APIs so we treat it as a black box but still pull telemetry from it. Observability must be end-to-end with distributed tracing, centralized logging, and region-specific dashboards so we can monitor latency, data lineage, and compliance events in real time without relying on any one vendor's proprietary tooling.",
  "non_functional_requirements": "For the PoC, we need to demonstrate sub-two-second response times for customer lookups under at least a few hundred concurrent users, with streaming updates applied in near real time. By the two-year rollout, the platform must scale to tens of thousands of concurrent sessions globally, sustain peak loads without falling back to batch, and guarantee consistency of the customer object within seconds. Anything slower or less scalable will fail to prove viability."
}
